{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPS7mqQc92mW"
      },
      "source": [
        "This notebook is ued to train and evaluate OncoPlex on the pan cancer dataset\n",
        "\n",
        "- Load the data preprocessed previously\n",
        "- Model class\n",
        "- Train and eval functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjEkXghT37l0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        " \n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv, ChebConv, GATConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import precision_recall_curve, auc, f1_score, roc_auc_score\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCkj1xgo_DN5"
      },
      "source": [
        "# Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkfFdMfYZwqg"
      },
      "outputs": [],
      "source": [
        "class conv_layer(nn.Module):\n",
        "    def __init__(self, in_ft, out_ft, bias=True):\n",
        "        super(conv_layer, self).__init__()\n",
        "\n",
        "        self.weight = Parameter(torch.Tensor(in_ft, out_ft))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_ft))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, G: torch.Tensor):\n",
        "        x = x.matmul(self.weight)\n",
        "        if self.bias is not None:\n",
        "            x = x + self.bias\n",
        "        x = G.matmul(x)\n",
        "        return x\n",
        "\n",
        "#===========================================================\n",
        "class HGCN_layer(nn.Module):\n",
        "    def __init__(self, n_hid, dropout=0.5):\n",
        "        super(HGCN_layer, self).__init__()\n",
        "        self.hgc1 = conv_layer(n_hid, n_hid)\n",
        "        self.act = nn.LeakyReLU()\n",
        "        self.dropout = dropout  \n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = self.hgc1(x, G)\n",
        "        x = self.act(x)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        return x\n",
        "\n",
        "#=======================================================\n",
        "class HD_sim(nn.Module):\n",
        "    def __init__(self, h_dim, dropout=0.5):\n",
        "        super(HD_sim, self).__init__()\n",
        "        self.HD1 = HGCN_layer(h_dim)\n",
        "        self.emb = nn.Linear(h_dim, h_dim)\n",
        "        #self.norm = nn.LayerNorm(h_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = F.leaky_relu_(self.HD1(x, G))\n",
        "        x1 = self.emb(x)\n",
        "        #x1 = self.norm(x1)\n",
        "        x1 += x  # residual\n",
        "        return x1\n",
        "\n",
        "#=============================================================\n",
        "class OncoNet(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, out_dim, num_layer=3, dropout=0.5):\n",
        "        super(OncoNet, self).__init__()\n",
        "\n",
        "        \n",
        "        self.mlp = nn.Linear(in_dim, hid_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList([HD_sim(hid_dim, dropout) for _ in range(num_layer)])\n",
        "        self.fc2 = nn.Linear(hid_dim, out_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = F.leaky_relu(self.mlp(x))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, G)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAkRsWVA-zP4"
      },
      "source": [
        "# Pan cancer training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "def cal_auc(y_true, y_pred):\n",
        "     pred = y_pred.cpu().detach().numpy()\n",
        "     pred= np.exp(pred)\n",
        "     pred = pred[:,1]\n",
        "    # pred = (torch.sigmoid(y_pred) > 0.5).float()\n",
        "     true = y_true.cpu().numpy()\n",
        "     AUROC = roc_auc_score(true, pred)\n",
        "     precision, recall, thresholds = precision_recall_curve(true, pred)\n",
        "     AUPRC = auc(recall, precision)\n",
        "     return AUROC, AUPRC\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "   # pred=(torch.sigmoid(y_pred)>0.5).float()\n",
        "    pred=torch.argmax(y_pred,dim=1).cpu().numpy()\n",
        "    true=y_true.cpu().numpy()\n",
        "    acc = (pred == true).mean()\n",
        "    return acc\n",
        "\n",
        "\n",
        "def f1_score_(y_true, y_pred):\n",
        "    pred = y_pred.cpu().detach().numpy()\n",
        "    pred = np.exp(pred)\n",
        "    pred = (pred[:,1] > 0.5).astype(float)\n",
        "    true = y_true.cpu().numpy()\n",
        "    f1 = f1_score(true, pred)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Train, validation, and test \n",
        "def train(model, optimizer, x, G, y, train_idx, weight):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[train_idx], y[train_idx], weight=torch.tensor(weight))\n",
        "    train_auroc, train_auprc = cal_auc(y[train_idx], logits[train_idx])\n",
        "    train_f1 = f1_score_(y[train_idx], logits[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item(), train_auroc, train_auprc, train_f1\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def val(model, x, G, y, val_idx, weight):\n",
        "    model.eval()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[val_idx], y[val_idx], weight=torch.tensor(weight))\n",
        "    val_acc = accuracy_fn(y[val_idx], logits[val_idx])\n",
        "    val_auroc, val_auprc = cal_auc(y[val_idx], logits[val_idx])\n",
        "    val_f1 = f1_score_(y[val_idx], logits[val_idx])\n",
        "    return loss.item(), val_acc, val_auroc, val_auprc, val_f1\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, x, G, y, test_idx, nodes, unknown_idx, weight):\n",
        "    model.eval()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[test_idx], y[test_idx], weight=torch.tensor(weight))\n",
        "    test_acc = accuracy_fn(y[test_idx], logits[test_idx])\n",
        "    test_auroc, test_auprc = cal_auc(y[test_idx], logits[test_idx])\n",
        "    test_f1 = f1_score_(y[test_idx], logits[test_idx])\n",
        "\n",
        "    test_genes = [nodes[i] for i in test_idx]\n",
        "    unknown_genes = [nodes[i] for i in unknown_idx]\n",
        "\n",
        "    prob_test = logits.exp().detach().cpu().numpy()[test_idx]\n",
        "    prob_unknown = logits.exp().detach().cpu().numpy()[unknown_idx]\n",
        "\n",
        "    test_results = pd.DataFrame(prob_test, index=test_genes, columns=[\"non_driver\", \"driver\"])\n",
        "    unknown_results = pd.DataFrame(prob_unknown, index=unknown_genes, columns=[\"non_driver\", \"driver\"])\n",
        "    final_results = pd.concat([test_results, unknown_results])\n",
        "\n",
        "    return loss.item(), test_acc, test_auroc, test_auprc, test_f1, final_results, test_results, unknown_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def main(seed):\n",
        "    # Set device and seeds\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    num_epochs = 300\n",
        "    patience = 20\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    data = load_data('drive/MyDrive/OncoPlex/cancer_data/TCGA/processed/OncoPlex_dataset.pkl')\n",
        "   \n",
        "    # Check \n",
        "    data.keys()\n",
        "   # cancer_nodes = [nodes for nodes, label in zip(data['nodes'], data['label']) if label == 1]\n",
        "   # len(cancer_nodes)\n",
        "\n",
        "   # nc_nodes = [nodes for nodes, label in zip(data['nodes'], data['label']) if label == 0]\n",
        "   # len(nc_nodes), len(cancer_nodes)\n",
        "\n",
        "    x = data['pancancer']['core_features'].to(device)  # if used comprehensive features, change it to comp\n",
        "   #x = torch.eye(x.shape[0], device=device) # this for incidence based features\n",
        "    y = torch.tensor(data['pancancer']['label'], dtype=torch.long).to(device)\n",
        "    G = torch.tensor(data['pancancer']['edge_index'], dtype=torch.float).to(device)\n",
        "\n",
        "    \n",
        "    known_idx = torch.where((y== 1) | (y== 0))[0].to(device)\n",
        "    unknown_idx = torch.where(y== -1)[0].to(device)\n",
        "\n",
        "    train_idx, test_idx = torch.tensor(data['pancancer']['train_idx'], dtype=torch.long).to(device), torch.tensor(data['pancancer']['test_idx'], dtype=torch.long).to(device)\n",
        "    nodes = data['pancancer']['nodes']\n",
        "\n",
        "    param_grid = {\n",
        "        'lr': [0.001, 0.005, 0.0005],\n",
        "        'weight_decay': [0.001, 0.0001],\n",
        "        'hidden_dim': [128, 64, 256],\n",
        "        'dropout': [0.5, 0.4, 0.25],\n",
        "        'num_layers': [2, 3, 4],\n",
        "        'class_weight': [[1.0, 0.4], [1.0, 0.2]]\n",
        "    }\n",
        "\n",
        "    outer_k = 5\n",
        "    inner_k = 3\n",
        "    outer_kfold = StratifiedKFold(n_splits=outer_k, shuffle=True, random_state=seed)\n",
        "    outer_results = []\n",
        "\n",
        "    for fold, (train_val_idx, test_idx) in enumerate(outer_kfold.split(x[train_idx], y[train_idx])):\n",
        "        print(f\"\\n Outer Fold {fold + 1}/{outer_k}\")\n",
        "\n",
        "        best_hyperparams = None\n",
        "        best_val_loss = float('inf')\n",
        "\n",
        "        inner_kfold = StratifiedKFold(n_splits=inner_k, shuffle=True, random_state=seed)\n",
        "\n",
        "        for params in ParameterGrid(param_grid):\n",
        "            val_losses = []\n",
        "\n",
        "            for inner_train_idx, inner_val_idx in inner_kfold.split(x[train_val_idx], y[train_val_idx]):\n",
        "                model = OncoNet(\n",
        "                    x.shape[1],\n",
        "                    hid_dim=params['hidden_dim'],\n",
        "                    num_layer=params['num_layers'],\n",
        "                    dropout=params['dropout'],\n",
        "                    out_dim=2\n",
        "                )\n",
        "                optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "\n",
        "                best_inner_val_loss = float('inf')\n",
        "                patience_counter = 0\n",
        "\n",
        "                for epoch in range(num_epochs):\n",
        "                    train_loss, *_ = train(model, optimizer, x, G, y, inner_train_idx, weight=params['class_weight'])\n",
        "                    val_loss, *_ = val(model, x, G, y, inner_val_idx, weight=params['class_weight'])\n",
        "\n",
        "                    if val_loss < best_inner_val_loss:\n",
        "                        best_inner_val_loss = val_loss\n",
        "                        patience_counter = 0\n",
        "                    else:\n",
        "                        patience_counter += 1\n",
        "                        if patience_counter >= patience:\n",
        "                            print(f\"  Early stopping at epoch {epoch + 1} in inner fold (no improvement for {patience} epochs)\")\n",
        "                            break\n",
        "\n",
        "                val_losses.append(best_inner_val_loss)\n",
        "\n",
        "            avg_val_loss = np.mean(val_losses)\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                best_hyperparams = params\n",
        "\n",
        "        print(f\"Best hyperparameters for fold {fold + 1}: {best_hyperparams}\")\n",
        "\n",
        "        model = OncoNet(\n",
        "            x.shape[1],\n",
        "            hid_dim=best_hyperparams['hidden_dim'],\n",
        "            num_layer=best_hyperparams['num_layers'],\n",
        "            dropout=best_hyperparams['dropout'],\n",
        "            out_dim=2\n",
        "        )\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=best_hyperparams['lr'], weight_decay=best_hyperparams['weight_decay'])\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss, *_ = train(model, optimizer, x, G, y, train_val_idx, weight=best_hyperparams['class_weight'])\n",
        "\n",
        "        test_loss, test_acc, test_auroc, test_auprc, test_f1, final_results, test_results, unknown_results = test(model, optimizer, x, G, y, test_idx, nodes, unknown_idx, weight=best_hyperparams['class_weight'])\n",
        "\n",
        "        outer_results.append({\n",
        "            'test_loss': test_loss,\n",
        "            'test_acc': test_acc,\n",
        "            'test_auroc': test_auroc,\n",
        "            'test_auprc': test_auprc,\n",
        "            'test_f1': test_f1\n",
        "        })\n",
        "\n",
        "        fold_dir = f\"results/pan_cancer/fold_{fold+1}\"\n",
        "        os.makedirs(fold_dir, exist_ok=True)\n",
        "        test_results.to_csv(f\"{fold_dir}/test_results.csv\")\n",
        "        unknown_results.to_csv(f\"{fold_dir}/unknown_results.csv\")\n",
        "        final_results.to_csv(f\"{fold_dir}/final_results.csv\")\n",
        "\n",
        "    metrics_df = pd.DataFrame(outer_results)\n",
        "    mean_metrics = metrics_df.mean()\n",
        "    std_metrics = metrics_df.std()\n",
        "\n",
        "    summary_df = pd.DataFrame({\n",
        "        \"Metric\": mean_metrics.index,\n",
        "        \"Mean\": mean_metrics.values,\n",
        "        \"Std\": std_metrics.values\n",
        "    })\n",
        "    summary_dir = \"results/pan_cancer\"\n",
        "    summary_df.to_csv(os.path.join(summary_dir, \"outer_fold_summary.csv\"), index=False)\n",
        "\n",
        "    print(\"\\nAverage Results Across Outer Folds:\")\n",
        "    print(summary_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    seed = 42\n",
        "    print(f\"Starting training with seed {seed}...\")\n",
        "    main(seed)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
