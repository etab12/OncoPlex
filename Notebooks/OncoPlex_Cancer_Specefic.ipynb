{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g-Ls2IN4NEi"
      },
      "source": [
        "This notebook is ued to train and evaluate OncoPlex on the cancer-specific dataset\n",
        "\n",
        "- Load the data preprocessed previously \n",
        "- Model class\n",
        "- Train and eval for the individual cancers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "import os \n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv, LayerNorm, HypergraphConv\n",
        "from torch.nn import Dropout, Parameter\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class conv_layer(nn.Module):\n",
        "    def __init__(self, in_ft, out_ft, bias=True):\n",
        "        super(conv_layer, self).__init__()\n",
        "\n",
        "        self.weight = Parameter(torch.Tensor(in_ft, out_ft))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_ft))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, G: torch.Tensor):\n",
        "        x = x.matmul(self.weight)\n",
        "        if self.bias is not None:\n",
        "            x = x + self.bias\n",
        "        x = G.matmul(x)\n",
        "        return x\n",
        "\n",
        "#===========================================================\n",
        "class HGCN_layer(nn.Module):\n",
        "    def __init__(self, n_hid, dropout=0.5):\n",
        "        super(HGCN_layer, self).__init__()\n",
        "        self.hgc1 = conv_layer(n_hid, n_hid)\n",
        "        self.act = nn.LeakyReLU()\n",
        "        self.dropout = dropout  \n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = self.hgc1(x, G)\n",
        "        x = self.act(x)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        return x\n",
        "\n",
        "#=======================================================\n",
        "class HD_sim(nn.Module):\n",
        "    def __init__(self, h_dim, dropout=0.5):\n",
        "        super(HD_sim, self).__init__()\n",
        "        self.HD1 = HGCN_layer(h_dim)\n",
        "        self.emb = nn.Linear(h_dim, h_dim)\n",
        "        #self.norm = nn.LayerNorm(h_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = F.leaky_relu_(self.HD1(x, G))\n",
        "        x1 = self.emb(x)\n",
        "        #x1 = self.norm(x1)\n",
        "        x1 += x  # residual\n",
        "        return x1\n",
        "\n",
        "#=============================================================\n",
        "class OncoNet(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, out_dim, num_layer=3, dropout=0.5):\n",
        "        super(OncoNet, self).__init__()\n",
        "\n",
        "        \n",
        "        self.mlp = nn.Linear(in_dim, hid_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList([HD_sim(hid_dim, dropout) for _ in range(num_layer)])\n",
        "        self.fc2 = nn.Linear(hid_dim, out_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, G):\n",
        "        x = F.leaky_relu(self.mlp(x))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, G)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z877IXfjBmBt"
      },
      "source": [
        "# Train and evaluate for 11 Cancer type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have all the data for each cancer, just we need to aupload it here and train the model \n",
        "\n",
        "All the results with the predictions will be saved "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSoOmh25z4iu",
        "outputId": "83b56fe9-435d-4332-c588-00bbbfe6e1f3"
      },
      "outputs": [],
      "source": [
        "def cal_auc(y_true, y_pred):\n",
        "     pred = y_pred.cpu().detach().numpy()\n",
        "     pred= np.exp(pred)\n",
        "     pred = pred[:,1]\n",
        "     # pred = (torch.sigmoid(y_pred) > 0.5).float()\n",
        "     true = y_true.cpu().numpy()\n",
        "     AUROC = roc_auc_score(true, pred)\n",
        "     precision, recall, thresholds = precision_recall_curve(true, pred)\n",
        "     AUPRC = auc(recall, precision)\n",
        "     return AUROC, AUPRC\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "   # pred=(torch.sigmoid(y_pred)>0.5).float()\n",
        "    pred=torch.argmax(y_pred,dim=1).cpu().numpy()\n",
        "    true=y_true.cpu().numpy()\n",
        "    acc = (pred == true).mean()\n",
        "    return acc\n",
        "\n",
        "\n",
        "def f1_score_(y_true, y_pred):\n",
        "    pred = y_pred.cpu().detach().numpy()\n",
        "    pred = np.exp(pred)\n",
        "    pred = (pred[:,1] > 0.5).astype(float)\n",
        "    true = y_true.cpu().numpy()\n",
        "    f1 = f1_score(true, pred)\n",
        "    return f1\n",
        " \n",
        "# ===========================================================================================\n",
        "def train(model, optimizer, x, G, y, train_idx, weight):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[train_idx], y[train_idx], weight=torch.tensor(weight))\n",
        "    train_auroc, train_auprc = cal_auc(y[train_idx], logits[train_idx])\n",
        "    train_f1 = f1_score_(y[train_idx], logits[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item(), train_auroc, train_auprc, train_f1\n",
        "\n",
        "@torch.no_grad()\n",
        "def val(model, x, G, y, val_idx, weight):\n",
        "    model.eval()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[val_idx], y[val_idx], weight=torch.tensor(weight))\n",
        "    val_acc = accuracy_fn(y[val_idx], logits[val_idx])\n",
        "    val_auroc, val_auprc = cal_auc(y[val_idx], logits[val_idx])\n",
        "    val_f1 = f1_score_(y[val_idx], logits[val_idx])\n",
        "    return loss.item(), val_acc, val_auroc, val_auprc, val_f1\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, x, G, y, test_idx, nodes, unknown_idx, weight):\n",
        "    model.eval()\n",
        "    logits = model(x, G)\n",
        "    loss = F.nll_loss(logits[test_idx], y[test_idx], weight=torch.tensor(weight))\n",
        "    test_acc = accuracy_fn(y[test_idx], logits[test_idx])\n",
        "    test_auroc, test_auprc = cal_auc(y[test_idx], logits[test_idx])\n",
        "    test_f1 = f1_score_(y[test_idx], logits[test_idx])\n",
        "\n",
        "    test_genes = [nodes[i] for i in test_idx]\n",
        "    unknown_genes = [nodes[i] for i in unknown_idx]\n",
        "\n",
        "    prob_test = logits.exp().detach().cpu().numpy()[test_idx]\n",
        "    prob_unknown = logits.exp().detach().cpu().numpy()[unknown_idx]\n",
        "\n",
        "    test_results = pd.DataFrame(prob_test, index=test_genes, columns=[\"non_driver\", \"driver\"])\n",
        "    unknown_results = pd.DataFrame(prob_unknown, index=unknown_genes, columns=[\"non_driver\", \"driver\"])\n",
        "    final_results = pd.concat([test_results, unknown_results])\n",
        "\n",
        "    return loss.item(), test_acc, test_auroc, test_auprc, test_f1, final_results, test_results, unknown_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        cancer_data = pickle.load(f)\n",
        "    return cancer_data\n",
        "\n",
        "\n",
        "def main(seed):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        " \n",
        "    num_epoch = 200\n",
        "    patience = 20\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Load all saved cancer datasets\n",
        "    print(\"Loading specefic datasets\")\n",
        "    dataset_path = 'drive/MyDrive/OncoPlex/OncoPlex_datasets.pkl'\n",
        "    cancer_data = load_data(dataset_path)\n",
        "    \n",
        "\n",
        "    param_grid = {\n",
        "        'lr': [0.001, 0.0005, 0.005],\n",
        "        'weight_decay': [0.001, 0.0001],\n",
        "        'hidden_dim': [128, 64, 256],\n",
        "        'dropout': [0.5, 0.4, 0.25],\n",
        "        'num_layers': [2, 3, 4],\n",
        "        'class_weight': [[1.0, 0.4], [1.0, 0.2], [1.0, 0.45]]\n",
        "    }\n",
        "\n",
        "    outer_k = 5\n",
        "    inner_k = 3\n",
        "\n",
        "    for cancer in cancer_data.keys():\n",
        "        if cancer == 'pancancer':\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n\\n Cancer Type: {cancer} \")\n",
        "\n",
        "        x = cancer_data[cancer]['core_features']  # or comp features \n",
        "        x_ = torch.tensor(x, dtype=torch.float32).to(device)\n",
        "\n",
        "        y = cancer_data[cancer]['label']\n",
        "        y_ = torch.tensor(y, dtype=torch.long).to(device)\n",
        "\n",
        "        edge_index = cancer_data[cancer]['edge_index']\n",
        "        G_ = torch.tensor(edge_index, dtype=torch.float32).to(device)\n",
        "\n",
        "        known_idx = torch.where((y_ == 1) | (y_ == 0))[0].to(device)\n",
        "        unknown_idx = torch.where(y_ == -1)[0].to(device)\n",
        "\n",
        "        train_idx = torch.tensor(cancer_data[cancer]['train_idx'], dtype=torch.long).to(device)\n",
        "        test_idx = torch.tensor(cancer_data[cancer]['test_idx'], dtype=torch.long).to(device)\n",
        "        nodes = cancer_data[cancer]['nodes']\n",
        "        #=====================================================\n",
        "        outer_results = []\n",
        "        outer_kfold = StratifiedKFold(n_splits=outer_k, shuffle=True, random_state=seed)\n",
        "\n",
        "        for fold, (train_val_idx, test_idx) in enumerate(outer_kfold.split(x_[train_idx], y_[train_idx])):\n",
        "            print(f\"\\n=== Outer Fold {fold+1}/{outer_k} ===\")\n",
        "\n",
        "            assert len(set(train_val_idx.tolist()) & set(test_idx.tolist())) == 0\n",
        "\n",
        "            inner_kfold = StratifiedKFold(n_splits=inner_k, shuffle=True, random_state=seed)\n",
        "            best_hyperparams = None\n",
        "            best_val_loss = float('inf')\n",
        "            best_inner_metrics = None\n",
        "\n",
        "            for params in ParameterGrid(param_grid):\n",
        "                val_losses = []\n",
        "                val_metrics = {'val_acc': [], 'val_auroc': [], 'val_auprc': [], 'val_f1': []}\n",
        "\n",
        "                for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kfold.split(x_[train_val_idx], y_[train_val_idx])):\n",
        "                    assert len(set(inner_train_idx.tolist()) & set(inner_val_idx.tolist())) == 0\n",
        "\n",
        "                    model = OncoNet(in_dim=x_.shape[1], hid_dim=params['hidden_dim'], out_dim=2, num_layer=params['num_layers'], dropout=params['dropout'])\n",
        "                    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "\n",
        "                    best_inner_val_loss = float('inf')\n",
        "                    patience_counter = 0\n",
        "\n",
        "                    for epoch in range(num_epoch):\n",
        "                        train_loss, _, _, _ = train(model, optimizer,  x_, G_, y_, inner_train_idx, weight=params['class_weight'])\n",
        "                        val_loss, val_acc, val_auroc, val_auprc, val_f1 = val(model, x_, G_, y_, inner_val_idx, weight=params['class_weight'])\n",
        "\n",
        "                        if val_loss < best_inner_val_loss:\n",
        "                            best_inner_val_loss = val_loss\n",
        "                            patience_counter = 0\n",
        "                        else:\n",
        "                            patience_counter += 1\n",
        "                            if patience_counter >= patience:\n",
        "                                print(f\" Early stopping at epoch {epoch+1} in inner fold {inner_fold+1} (no improvement for {patience} epochs)\")\n",
        "                                break\n",
        "\n",
        "                    val_losses.append(best_inner_val_loss.item())\n",
        "                    val_metrics['val_acc'].append(val_acc)\n",
        "                    val_metrics['val_auroc'].append(val_auroc)\n",
        "                    val_metrics['val_auprc'].append(val_auprc)\n",
        "                    val_metrics['val_f1'].append(val_f1)\n",
        "\n",
        "                avg_val_loss = np.mean(val_losses)\n",
        "                if avg_val_loss < best_val_loss:\n",
        "                    best_val_loss = avg_val_loss\n",
        "                    best_hyperparams = params\n",
        "                    best_inner_metrics = {\n",
        "                        'val_loss': avg_val_loss,\n",
        "                        'val_acc': np.mean(val_metrics['val_acc']),\n",
        "                        'val_auroc': np.mean(val_metrics['val_auroc']),\n",
        "                        'val_auprc': np.mean(val_metrics['val_auprc']),\n",
        "                        'val_f1': np.mean(val_metrics['val_f1'])\n",
        "                    }\n",
        "\n",
        "            print(f\"\\nBest hyperparameters for Outer Fold {fold+1}: {best_hyperparams}\")\n",
        "\n",
        "            model = OncoNet(in_dim=x_.shape[1], hid_dim=best_hyperparams['hidden_dim'], out_dim=2, num_layer=best_hyperparams['num_layers'], dropout=best_hyperparams['dropout'])\n",
        "            optimizer = torch.optim.AdamW(model.parameters(), lr=best_hyperparams['lr'], weight_decay=best_hyperparams['weight_decay'])\n",
        "\n",
        "            for epoch in range(num_epoch):\n",
        "                print(f\"Training Outer Fold {fold+1}, Epoch {epoch+1}/{num_epoch}\")\n",
        "                train_loss, train_auroc, train_auprc, train_f1 = train(model, optimizer, x_, G_, y_, train_val_idx, weight=best_hyperparams['class_weight'])\n",
        "\n",
        "            test_loss, test_acc, auroc_test, auprc_test, test_f1, final_results, test_results, unknown_results = test(model, x_, G_, y_, test_idx, nodes, test_idx, weight=best_hyperparams['class_weight'])\n",
        "\n",
        "            outer_results.append({\n",
        "                'test_loss': test_loss.item(),\n",
        "                'test_acc': test_acc,\n",
        "                'test_auroc': auroc_test,\n",
        "                'test_auprc': auprc_test,\n",
        "                'test_f1': test_f1\n",
        "            })\n",
        " \n",
        "\n",
        "            result_dir = f\"results/{cancer}/outer_fold_{fold+1}\"\n",
        "            os.makedirs(result_dir, exist_ok=True)\n",
        "            test_results.to_csv(f\"{result_dir}/test_results.csv\")\n",
        "            unknown_results.to_csv(f\"{result_dir}/unknown_results.csv\")\n",
        "            final_results.to_csv(f\"{result_dir}/final_results.csv\")\n",
        "\n",
        "        metrics_df = pd.DataFrame(outer_results)\n",
        "        mean_metrics = metrics_df.mean()\n",
        "        std_metrics = metrics_df.std()\n",
        "        summary_df = pd.DataFrame({\n",
        "            \"Metric\": mean_metrics.index,\n",
        "            \"Mean\": mean_metrics.values,\n",
        "            \"Std\": std_metrics.values\n",
        "        })\n",
        " \n",
        "        summary_dir = f\"results/{cancer}\"\n",
        "        summary_df.to_csv(os.path.join(summary_dir, \"outer_fold_summary.csv\"), index=False)\n",
        "\n",
        "        \n",
        "\n",
        "        print(\"\\nAverage Results Across Outer Folds:\")\n",
        "        print(summary_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    seed = 42\n",
        "    print(f\"Starting training with seed {seed}...\")\n",
        "    main(seed)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
